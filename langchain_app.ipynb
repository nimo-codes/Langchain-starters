{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f31c4cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['OPENAI_API_KEY'] = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa352d5f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Carriage Classics\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "\n",
    "llm = OpenAI(temperature=0.9)\n",
    "name = llm.predict(\"I want to open a car shop, suggest me a elegent name\")\n",
    "print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a306b9d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I want to open a garage for Bugatti. Suggest a nice name for this.\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template_name = PromptTemplate(\n",
    "    input_variables =['car'],\n",
    "    template = \"I want to open a garage for {car}. Suggest a nice name for this.\"\n",
    ")\n",
    "p = prompt_template_name.format(car=\"Bugatti\")\n",
    "print(p)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba65c213",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\n\\nFerrari Elite Motors.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=prompt_template_name)\n",
    "chain.run(\"Ferrari\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5ccee75",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mI want to open a garage for Bugatti. Suggest a nice name for this.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\nBugatti Autoworld.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = LLMChain(llm=llm, prompt=prompt_template_name, verbose=True)\n",
    "chain.run(\"Bugatti\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "21098937",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0.6)\n",
    "\n",
    "prompt_template_name = PromptTemplate(\n",
    "    input_variables =['car'],\n",
    "    template = \"I want to open a garage for {car}. Suggest a nice name for this.\"\n",
    ")\n",
    "\n",
    "name_chain =LLMChain(llm=llm, prompt=prompt_template_name)\n",
    "\n",
    "prompt_template_items = PromptTemplate(\n",
    "    input_variables = ['diff_cars'],\n",
    "    template=\"Suggest me some cars for {diff_cars}\"\n",
    ")\n",
    "\n",
    "car_items = LLMChain(llm=llm, prompt=prompt_template_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d9fd9a79",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. Bugatti Chiron \n",
      "2. Bugatti Veyron \n",
      "3. Bugatti Divo \n",
      "4. Lamborghini Aventador \n",
      "5. Lamborghini Huracan \n",
      "6. Aston Martin DB11 \n",
      "7. Rolls Royce Wraith \n",
      "8. Ferrari 488 GTB \n",
      "9. McLaren 720s \n",
      "10. Bentley Continental GT\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import SimpleSequentialChain\n",
    "chain = SimpleSequentialChain(chains = [name_chain, car_items])\n",
    "\n",
    "content = chain.run(\"Bugatti\")\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "49dc0fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0.7)\n",
    "\n",
    "prompt_template_name = PromptTemplate(\n",
    "    input_variables =['car'],\n",
    "    template = \"I want to open a garage for {car}. Suggest a nice name for this.\"\n",
    ")\n",
    "\n",
    "name_chain =LLMChain(llm=llm, prompt=prompt_template_name, output_key=\"diff_cars\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9dea8402",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0.7)\n",
    "\n",
    "prompt_template_items = PromptTemplate(\n",
    "    input_variables = ['diff_cars'],\n",
    "    template=\"Suggest me some cars for {diff_cars}.\"\n",
    ")\n",
    "\n",
    "car_items_chain =LLMChain(llm=llm, prompt=prompt_template_items, output_key=\"name_of_cars\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1ec1be10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SequentialChain\n",
    "\n",
    "chain = SequentialChain(\n",
    "    chains = [name_chain, car_items_chain],\n",
    "    input_variables = ['car'],\n",
    "    output_variables = ['diff_cars', \"name_of_cars\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4653c540",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'car': 'ferrari',\n",
       " 'diff_cars': '\\n\\nFerrari Elite Garage',\n",
       " 'name_of_cars': '\\n\\n1. Ferrari 458 Italia\\n2. Ferrari F8 Tributo\\n3. Ferrari 488 Pista\\n4. Ferrari GTC4Lusso\\n5. Ferrari 812 Superfast\\n6. Ferrari Portofino\\n7. Ferrari SF90 Stradale\\n8. Ferrari F12tdf\\n9. Ferrari LaFerrari Aperta\\n10. Ferrari 488 Spider'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain({\"car\": \"ferrari\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5e6ee719",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f492fb5a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NoneType"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(chain.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "53eea298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Maruti Suzuki Garage Plus\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory()\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=prompt_template_name, memory=memory)\n",
    "name = chain.run(\"maruti suzuki\")\n",
    "print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0de5d50b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Toyota Garage Plus\n"
     ]
    }
   ],
   "source": [
    "name = chain.run(\"toyota\")\n",
    "print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5cc88888",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: maruti suzuki\n",
      "AI: \n",
      "\n",
      "Maruti Suzuki Garage Plus\n",
      "Human: toyota\n",
      "AI: \n",
      "\n",
      "Toyota Garage Plus\n"
     ]
    }
   ],
   "source": [
    "print(chain.memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "687ddd2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "{history}\n",
      "Human: {input}\n",
      "AI:\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "\n",
    "convo = ConversationChain(llm=OpenAI(temperature=0.7))\n",
    "print(convo.prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "47ad5062",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The first Indian President was Dr. Rajendra Prasad, who served from 1950 to 1962.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convo.run(\"what is the name of the first indian president?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "03c80b54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' 11.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convo.run(\"How much is 5+6?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "07342f88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Dr. Rajendra Prasad died on February 28, 1963.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convo.run(\"when did he die?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4e459d07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Who won the first cricket world cup?\n",
      "AI:  The first Cricket World Cup was won by the West Indies in 1975.\n",
      "Human: How much is 5+5?\n",
      "AI:  10.\n",
      "Human: Who was the captain ofthe winning team?\n",
      "AI:  The captain of the West Indies team that won the first Cricket World Cup in 1975 was Clive Lloyd.\n"
     ]
    }
   ],
   "source": [
    "print(convo.memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "460eb33c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The first Cricket World Cup was held in 1975 and the winner was the West Indies.'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "\n",
    "memory = ConversationBufferWindowMemory(k=1)\n",
    "\n",
    "convo = ConversationChain(\n",
    "    llm=OpenAI(temperature=0.7),\n",
    "    memory=memory\n",
    ")\n",
    "convo.run(\"Who won the first cricket world cup?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d395beaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' 5+5 is 10.'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convo.run(\"How much is 5+5?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "93b24745",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" I'm sorry, I don't know.\""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convo.run(\"Who was the captain of the winning team?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
